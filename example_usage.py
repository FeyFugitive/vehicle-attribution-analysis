#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•´è½¦è®¢å•å½’å› åˆ†æä½¿ç”¨ç¤ºä¾‹
"""

import pandas as pd
import numpy as np
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import ANALYSIS_CONFIG, DATA_CONFIG
from utils import (
    build_optimized_paths, 
    removal_effect_optimized, 
    safe_category_mapping,
    validate_data_quality,
    log_analysis_progress
)

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    print("ğŸ“Š åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    n_records = 100
    sample_data = pd.DataFrame({
        'wish_create_time': pd.date_range('2023-01-01', periods=n_records, freq='D'),
        'intention_payment_time': pd.date_range('2023-01-01', periods=n_records, freq='D'),
        'deposit_payment_time': pd.date_range('2023-01-01', periods=n_records, freq='D'),
        'lock_time': pd.date_range('2023-01-01', periods=n_records, freq='D'),
        'final_payment_time': pd.date_range('2023-01-01', periods=n_records, freq='D'),
        'delivery_date': pd.date_range('2023-01-01', periods=n_records, freq='D'),
        'big_channel_name': ['é—¨åº—'] * 60 + ['æ€»éƒ¨'] * 40,
        'province_name': ['æµ™æ±Ÿçœ'] * 40 + ['æ±Ÿè‹çœ'] * 30 + ['å¹¿ä¸œçœ'] * 30,
        'series': ['LS6'] * 50 + ['LS7'] * 30 + ['LS8'] * 20,
        'order_status': ['å·²å®Œæˆ'] * 40 + ['è¿›è¡Œä¸­'] * 60
    })
    
    # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼ï¼Œè®©éƒ¨åˆ†è®¢å•ä¸å®Œæˆè½¬åŒ–
    sample_data.loc[10:20, 'intention_payment_time'] = None
    sample_data.loc[30:40, 'deposit_payment_time'] = None
    sample_data.loc[50:70, 'delivery_date'] = None  # è®©éƒ¨åˆ†è®¢å•ä¸å®Œæˆè½¬åŒ–
    
    return sample_data

def demonstrate_path_building():
    """æ¼”ç¤ºè·¯å¾„æ„å»ºåŠŸèƒ½"""
    print("\nğŸ”— æ¼”ç¤ºè·¯å¾„æ„å»ºåŠŸèƒ½")
    print("=" * 40)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    df = create_sample_data()
    
    # æ·»åŠ æ¸ é“åˆ†ç±»
    df["channel_category"] = df["big_channel_name"].apply(
        lambda x: safe_category_mapping(x, ANALYSIS_CONFIG['CHANNEL_MAPPING'])
    )
    
    # æ„å»ºè·¯å¾„
    paths = build_optimized_paths(df, "channel_category")
    
    print(f"æ„å»ºäº† {len(paths)} æ¡è·¯å¾„")
    print("ç¤ºä¾‹è·¯å¾„:")
    for i, path in enumerate(paths[:3]):
        print(f"  è·¯å¾„ {i+1}: {' -> '.join(path)}")
    
    return paths, df

def demonstrate_removal_effect():
    """æ¼”ç¤ºç§»é™¤æ•ˆåº”è®¡ç®—"""
    print("\nğŸ¯ æ¼”ç¤ºç§»é™¤æ•ˆåº”è®¡ç®—")
    print("=" * 40)
    
    paths, df = demonstrate_path_building()
    
    # å®šä¹‰æµ‹è¯•èŠ‚ç‚¹
    test_nodes = [
        f"Intention{ANALYSIS_CONFIG['PATH_SEPARATOR']}STORE",
        f"Deposit{ANALYSIS_CONFIG['PATH_SEPARATOR']}HQ"
    ]
    
    # è®¡ç®—ç§»é™¤æ•ˆåº”
    effects = removal_effect_optimized(paths, test_nodes)
    
    print("ç§»é™¤æ•ˆåº”ç»“æœ:")
    for node, effect in effects:
        print(f"  {node}: {effect:+.2f} pp")
    
    return effects

def demonstrate_data_validation():
    """æ¼”ç¤ºæ•°æ®è´¨é‡éªŒè¯"""
    print("\nğŸ” æ¼”ç¤ºæ•°æ®è´¨é‡éªŒè¯")
    print("=" * 40)
    
    df = create_sample_data()
    
    # éªŒè¯æ•°æ®è´¨é‡
    validation = validate_data_quality(df)
    
    print("æ•°æ®è´¨é‡æŠ¥å‘Š:")
    print(f"  æ€»è¡Œæ•°: {validation['total_rows']}")
    print(f"  é‡å¤è¡Œæ•°: {validation['duplicate_rows']}")
    
    if validation['missing_values']:
        print("  ç¼ºå¤±å€¼:")
        for col, count in validation['missing_values'].items():
            print(f"    {col}: {count}")
    
    print("  å”¯ä¸€å€¼æ•°é‡:")
    for col, count in validation['unique_values'].items():
        print(f"    {col}: {count}")

def demonstrate_config_usage():
    """æ¼”ç¤ºé…ç½®ä½¿ç”¨"""
    print("\nâš™ï¸ æ¼”ç¤ºé…ç½®ä½¿ç”¨")
    print("=" * 40)
    
    print("åˆ†æé…ç½®:")
    print(f"  Top Nçœä»½: {ANALYSIS_CONFIG['TOP_PROVINCES']}")
    print(f"  Top Nè½¦ç³»: {ANALYSIS_CONFIG['TOP_SERIES']}")
    print(f"  è·¯å¾„åˆ†éš”ç¬¦: '{ANALYSIS_CONFIG['PATH_SEPARATOR']}'")
    print(f"  æœªçŸ¥ç±»åˆ«: '{ANALYSIS_CONFIG['UNKNOWN_CATEGORY']}'")
    
    print("\næ•°æ®å¤„ç†é…ç½®:")
    print(f"  æ¸…æ´—è·³è·ƒå¼è®¢å•: {DATA_CONFIG['CLEAN_JUMP_ORDERS']}")
    print(f"  å¤„ç†ç¼ºå¤±å€¼: {DATA_CONFIG['HANDLE_MISSING_VALUES']}")
    print(f"  ä½¿ç”¨ç¨€ç–çŸ©é˜µ: {DATA_CONFIG['USE_SPARSE_MATRIX']}")

def demonstrate_error_handling():
    """æ¼”ç¤ºé”™è¯¯å¤„ç†"""
    print("\nğŸ›¡ï¸ æ¼”ç¤ºé”™è¯¯å¤„ç†")
    print("=" * 40)
    
    # æµ‹è¯•ç©ºå€¼å¤„ç†
    print("ç©ºå€¼å¤„ç†æµ‹è¯•:")
    mapping = {"é—¨åº—": "STORE", "æ€»éƒ¨": "HQ"}
    
    test_values = ["é—¨åº—", "æ€»éƒ¨", None, "", "   ", "å…¶ä»–"]
    for value in test_values:
        result = safe_category_mapping(value, mapping)
        print(f"  '{value}' -> '{result}'")
    
    # æµ‹è¯•è¾¹ç•Œæƒ…å†µ
    print("\nè¾¹ç•Œæƒ…å†µæµ‹è¯•:")
    empty_df = pd.DataFrame()
    paths = build_optimized_paths(empty_df, "channel_category")
    print(f"  ç©ºæ•°æ®æ¡†è·¯å¾„æ•°: {len(paths)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æ•´è½¦è®¢å•å½’å› åˆ†æ - ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        # 1. æ¼”ç¤ºè·¯å¾„æ„å»º
        demonstrate_path_building()
        
        # 2. æ¼”ç¤ºç§»é™¤æ•ˆåº”è®¡ç®—
        demonstrate_removal_effect()
        
        # 3. æ¼”ç¤ºæ•°æ®è´¨é‡éªŒè¯
        demonstrate_data_validation()
        
        # 4. æ¼”ç¤ºé…ç½®ä½¿ç”¨
        demonstrate_config_usage()
        
        # 5. æ¼”ç¤ºé”™è¯¯å¤„ç†
        demonstrate_error_handling()
        
        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("1. å‡†å¤‡çœŸå®æ•°æ®æ–‡ä»¶")
        print("2. è¿è¡Œ: python run_analysis.py")
        print("3. æŸ¥çœ‹åˆ†æç»“æœ")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 